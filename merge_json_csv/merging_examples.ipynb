{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with Python (so bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is why we don't use Python for this...\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# Open up both of our files\n",
    "with open(\"practice.json\", \"r\") as jsonfile, open(r\"visual_date.csv\", \"r\") as csv_file:\n",
    "    json_load = json.load(jsonfile)\n",
    "\n",
    "    # Where we're storing our dictionaries\n",
    "    list_of_dicts = []\n",
    "    # List to store the fips value we have already used\n",
    "    added_fips = []\n",
    "\n",
    "    # Loop through csv dicts\n",
    "    for elem in csv.DictReader(csv_file):\n",
    "        vis_dict = dict(elem)\n",
    "        \n",
    "        # Loop through json dicts & pull out anything you want for your final table\n",
    "        for i in range(len(json_load['features'])):\n",
    "            # Pull out the data we want, this returns a dictionary\n",
    "            properties = json_load['features'][i]['properties']\n",
    "            # Adding the polygon data to the properties dictionary\n",
    "            properties['coordinates'] = json_load['features'][i]['geometry']['coordinates']\n",
    "\n",
    "            # Get the fips value from our csv dict, we use this to check duplicates\n",
    "            new_fips = vis_dict['fips']\n",
    "            # Check the fips value to the list of fips values we have already used. (Duplicate chack)\n",
    "            if new_fips in added_fips:\n",
    "                continue\n",
    "            # Adjust the two values so they are same length. Visuals needs to be brought up to 5 digits, while Properties needs to be sliced down to 5.\n",
    "            elif vis_dict['fips'].rjust(5, '0') == properties['GEO_ID'][-5:]:\n",
    "                # Add fips value to our list which we use for duplicates\n",
    "                added_fips.append(new_fips)\n",
    "                # Use \"update\" to merge the dicts together\n",
    "                properties.update(vis_dict)\n",
    "                # Append the merged dict to our final list\n",
    "                list_of_dicts.append(properties)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "# This whole process takes over 1 minute to run...\n",
    "print(len(list_of_dicts))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is why we use Pandas instead...\n",
    "import pandas as pd\n",
    "\n",
    "# \"Converters\" parameter will format any strings less than 5 to have leading 0's.\n",
    "visualization = pd.read_csv(r\"visual_date.csv\", delimiter=',', header='infer', converters={'fips': '{:0>5}'.format})\n",
    "# Json contains latin characters\n",
    "geojson = pd.read_json(r\"practice.json\", encoding=\"latin-1\")\n",
    "\n",
    "# Visual dataframe\n",
    "visual_df = pd.DataFrame(visualization)\n",
    "\n",
    "# \"json_normalize\" will flatten jsons for us, converting \"keys\" to column names. ie, \"key.key.key = value\" depending on level\n",
    "# \"max_level\" parameter allows us to control how much of the json will be flattened.\n",
    "geo_df_pandas = pd.json_normalize(geojson['features'], max_level=1)\n",
    "\n",
    "# \"geo_df_pandas['properties.GEO_ID'].str[-5:]\" will reduce our string to last 5 digits for merging with \"fips\".\n",
    "# Visual data contained duplicates, needed to drop.\n",
    "merged = pd.merge(geo_df_pandas, visual_df, left_on=geo_df_pandas['properties.GEO_ID'].str[-5:], right_on=['fips'], how='inner').drop_duplicates(subset='fips')\n",
    "\n",
    "# Wow! Less than 10 seconds!\n",
    "# Python is a very slow language, Pandas is built off of a hybrid of Python & C referred to a \"Cython\" and will always out perform raw Python.\n",
    "display(merged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with SQL (loading the geosjon to postgresql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily doing this to load the json into postgres database, annoying issue with geojson.\n",
    "import json\n",
    "from sqlalchemy import create_engine, Column, Integer, String, JSON\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "\n",
    "def load_json_file(file_path, table_name):\n",
    "    # Create a connection to the database\n",
    "    engine = create_engine('postgresql://postgres:postgres@localhost:5432/psql_playground')\n",
    "\n",
    "    # Read the JSON file\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    # Create the table with the same name as the provided table name\n",
    "    Base = declarative_base()\n",
    "    class MyTable(Base):\n",
    "        __tablename__ = table_name\n",
    "        id = Column(Integer, primary_key=True)\n",
    "        data = Column(JSON)\n",
    "    Base.metadata.create_all(engine)\n",
    "    \n",
    "    # Create a session to add the data to the table\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "    record = MyTable(data=json_data)\n",
    "    session.add(record)\n",
    "    session.commit()\n",
    "\n",
    "# load the data\n",
    "load_json_file(\"practice.json\", \"json_table\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuilding Geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# import data to \n",
    "data = pd.read_csv(r\"map_data.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_json() returns a string of the data\n",
    "json_result_string = data.to_json(\n",
    "    orient='records', \n",
    "    double_precision=12,\n",
    "    date_format='iso'\n",
    ")\n",
    "\n",
    "# using json.loads() to convert string to json\n",
    "json_result = json.loads(json_result_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Polygon', 'coordinates': [[[-85.388717, 33.913044], [-85.380885, 33.873508], [-85.379455, 33.866291], [-85.377426, 33.856047], [-85.376403, 33.850656], [-85.364595, 33.788446], [-85.361844, 33.773951], [-85.360491, 33.767958], [-85.357402, 33.750104], [-85.355252, 33.739245], [-85.344054, 33.682684], [-85.342722, 33.675953], [-85.323792, 33.580339], [-85.31534, 33.537646], [-85.314994, 33.535898], [-85.314843, 33.534951], [-85.314091, 33.530218], [-85.313999, 33.529807], [-85.304439, 33.482884], [-85.308211, 33.481579], [-85.30925, 33.483137], [-85.314852, 33.487603], [-85.316028, 33.488267], [-85.320893, 33.488359], [-85.324856, 33.489161], [-85.331061, 33.491014], [-85.33828, 33.4947], [-85.342544, 33.495961], [-85.344923, 33.497608], [-85.346705, 33.501148], [-85.349958, 33.501216], [-85.351594, 33.4996], [-85.354491, 33.498866], [-85.352576, 33.494538], [-85.352573, 33.492438], [-85.355315, 33.49248], [-85.497455, 33.494624], [-85.501645, 33.494456], [-85.51731, 33.494524], [-85.52513, 33.494781], [-85.527515, 33.494608], [-85.539922, 33.494743], [-85.563763, 33.495081], [-85.565653, 33.494992], [-85.623387, 33.495371], [-85.623645, 33.495373], [-85.627835, 33.495624], [-85.643482, 33.495885], [-85.66722, 33.496293], [-85.680346, 33.496623], [-85.740983, 33.498376], [-85.765427, 33.498593], [-85.765308, 33.496862], [-85.765631, 33.483477], [-85.781244, 33.483625], [-85.782689, 33.483638], [-85.782735, 33.469349], [-85.887782, 33.469427], [-85.887675, 33.476768], [-85.870053, 33.476757], [-85.869308, 33.491574], [-85.852421, 33.491644], [-85.85189, 33.498742], [-85.849839, 33.49969], [-85.796852, 33.541849], [-85.796054, 33.55622], [-85.744118, 33.556075], [-85.742348, 33.586553], [-85.742202, 33.600002], [-85.737379, 33.599823], [-85.724517, 33.59943], [-85.724953, 33.613539], [-85.72367, 33.613492], [-85.72365, 33.613491], [-85.723074, 33.613505], [-85.689954, 33.612909], [-85.69014, 33.615815], [-85.690716, 33.625105], [-85.690684, 33.627789], [-85.674932, 33.627254], [-85.65581, 33.627166], [-85.655549, 33.638127], [-85.651295, 33.637972], [-85.651283, 33.64157], [-85.64719, 33.641529], [-85.64704, 33.648772], [-85.638579, 33.648413], [-85.638586, 33.649158], [-85.638049, 33.773339], [-85.621245, 33.773508], [-85.621019, 33.782331], [-85.62089, 33.787944], [-85.603469, 33.787755], [-85.603465, 33.788474], [-85.603391, 33.802344], [-85.585985, 33.802095], [-85.585201, 33.84592], [-85.636882, 33.846495], [-85.637126, 33.846497], [-85.637012, 33.875273], [-85.637014, 33.875944], [-85.601899, 33.874865], [-85.601913, 33.875101], [-85.601858, 33.88975], [-85.597063, 33.889703], [-85.532482, 33.889152], [-85.531812, 33.903049], [-85.530094, 33.941423], [-85.49582, 33.942394], [-85.495289, 33.95691], [-85.425627, 33.957069], [-85.425444, 33.960645], [-85.407831, 33.960548], [-85.407637, 33.964204], [-85.398837, 33.964129], [-85.391495, 33.927068], [-85.388717, 33.913044]]]}\n"
     ]
    }
   ],
   "source": [
    "# Using this to create personal reference points when reconstructing geojson\n",
    "with open(\"practice.json\", \"r\") as jsonfile:\n",
    "    json_load = json.load(jsonfile)\n",
    "\n",
    "    print(json_load['features'][0]['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuilding a geojson file\n",
    "import ast\n",
    "\n",
    "# Setup the container for our data\n",
    "geojson = {\n",
    "    'type': 'FeatureCollection',\n",
    "    'features': []\n",
    "}\n",
    "\n",
    "# Go through all the dictionaries. NOTE: remember our data is flat with no levels, we need to add levels to it.\n",
    "for record in json_result:\n",
    "    # I run these two lines of code once to create a output to reference when working on the geosjon\n",
    "    # print(record)\n",
    "    # break\n",
    "    \n",
    "    # Appending out features with data\n",
    "    geojson['features'].append({\n",
    "        'type': 'Feature',\n",
    "        'properties': {\n",
    "            'GEO_ID': record['properties.GEO_ID'],\n",
    "            'STATE': record['properties.STATE'],\n",
    "            'COUNTY': record['properties.COUNTY'],\n",
    "            'NAME': record['properties.NAME'],\n",
    "            'LSAD': record['properties.LSAD'],\n",
    "            'CENSUSAREA': record['properties.CENSUSAREA'],\n",
    "            'FIPS': record['FIPS'],\n",
    "            'recent_trend': record['recent_trend'],\n",
    "            'prediction_trend': record['prediction_trend'],\n",
    "            'O3_max_pred': record['O3_max_pred'],\n",
    "            'PM25_max_pred': record['PM25_max_pred'],\n",
    "            'future_prediction_trend': record['future_prediction_trend']\n",
    "        },\n",
    "        'geometry': {\n",
    "            'type': record['geometry.type'],\n",
    "            # ast.literal_eval() is a very efficient way to convert a \"string like list\" back to a real list\n",
    "            'coordinates': ast.literal_eval(record['geometry.coordinates']),\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally use json.dump() to output our dict to a json file.\n",
    "with open(\"map_data.json\", \"w\") as outfile:\n",
    "    json.dump(geojson, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65a8de41a5ee1eeefd8cde7b1d120363c7d2ff8e30a40d43c0887b207b60c148"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
